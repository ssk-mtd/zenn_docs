---
title: "音声可視化 discord bot を自作しました"
emoji: "🚀"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: [Go, Docker, Discord, React]
published: True
---


Discordのボイスチャットの状態を，ブラウザ上でリアルタイムに可視化したいと思ったので作ってみました．

# 構成
構成としては，Bot - サーバ - クライアント の3つに分けて構築します．
Go言語（Bot/サーバー）とReact（フロントエンド）を組み合わせ、UDPとWebSocketを活用して低遅延なオーディオビジュアライザーを構築しました．
それぞれの概要は以下になります．

1. **Sender (Discord Bot)**: Discordの音声ストリームを受信し，UDPで内部サーバーへ転送．
2. **Server (Go)**: UDPパケットを受け取り，Opusデコード処理を行った後、WebSocketでフロントエンドへ配信．
3. **Client (React)**: WebSocketからデータを受け取り，Web Audio APIとCanvasを使って描画．

また，全体のシーケンス図は以下のようになっています．（かっこわるい...）
![](/images/20251206_hoge/architect1215.png)

## 技術スタック
今回の実装で使ったものを並べておきます
**Backend**: Go 1.24 (Alpine)
* `github.com/bwmarrin/discordgo`: Discord APIクライアント
* `github.com/hraban/opus`: Opusコーデックのデコード
* `github.com/gorilla/websocket`: WebSocket通信

**Frontend**: React (Vite)
* Web Audio API (`AudioContext`, `AnalyserNode`)
* Canvas API

**Infrastructure**: Docker, Docker Compose


# 実装のポイント
## Bot
Discordのボイスチャット(VC)に接続し，受信した音声データをサーバに送信するだけの機能を持ったボットを構築しています．
基本の構成は[以前の記事](https://zenn.dev/dozenkomeda/articles/54c50ba3163f17)と同様であるため，ここでは割愛します．

重要な変更点として，discordから受信した音声データをUDPでサーバに送信するようにしています．
この際，ユーザを識別するためのSSRCを結合して送信しています．
この値は，ユーザごとに違うだけでなく，接続デバイスごとにも異なるようです．

```go
// sender/main.go (抜粋)
func audioUdpSender(conn *net.UDPConn, opusRecv <-chan *discordgo.Packet) {
    ssrcBuf := make([]byte, 4)
    for p := range opusRecv {
        if p.SSRC == 0 { continue }
        
        // SSRC (4byte) + Opus Data を結合してUDP送信
        binary.BigEndian.PutUint32(ssrcBuf, p.SSRC)
        payload := append(ssrcBuf, p.Opus...)
        
        conn.Write(payload)
    }
}

```

## Server
サーバでは，UDPで受け取ったパケットを可視化に適した形に変換しています．
今回Botから送られてくるデータは，先頭4バイトがSSRC，残りがOpus形式で圧縮された音声データです．なのでサーバー側で音声データをPCM (Raw Audio) にデコードし，SSRCと共にJSON形式でクライアントに投げます．

以下にサーバの実装の一部を記します．
特にudpで受信したデータの型の取り扱いには苦労したので，参考になれば幸いです．

```go
// server/main.go (抜粋)
type AudioPayload struct {
	SSRC uint32 `json:"ssrc"`
	PCM  []byte `json:"pcm"` // Base64エンコードされる
}

func startAudioServer(hub *Hub) {
	addr, _ := net.ResolveUDPAddr("udp", UdpPort)
	conn, err := net.ListenUDP("udp", addr)
	if err != nil {
		log.Fatal("UDP Listen Error:", err)
	}
	defer conn.Close()
	log.Printf("Listening for UDP Audio stream on %s...", UdpPort)

	decoder, err := opus.NewDecoder(SampleRate, Channels)
	if err != nil {
		log.Fatalf("Opus Init Error: %v", err)
	}

	udpBuf := make([]byte, 4096) // SSRC + Opus
	pcmBuf := make([]int16, 1920) // Max frame size

	for {
		n, _, err := conn.ReadFromUDP(udpBuf)
		if err != nil {
			log.Println("Read Error:", err)
			continue
		}
		opusData := udpBuf[4:n]
		ssrc := binary.BigEndian.Uint32(udpBuf[0:4])
		samples, err := decoder.Decode(opusData, pcmBuf)
		if err != nil {
			log.Println("Decode Error:", err)
			continue
		}

		byteData := make([]byte, samples*2)
		for i := 0; i < samples; i++ {
			binary.LittleEndian.PutUint16(byteData[i*2:], uint16(pcmBuf[i]))
		}

		payload := AudioPayload{
					SSRC: ssrc,
					PCM:  byteData, // raw PCM bytes
				}
		jsonBytes, err := json.Marshal(payload)
		if err != nil {
			log.Println(err)
		}

		hub.broadcast <- jsonBytes
	}
}
```
## Client
ここでは，React + Web Audio APIによる描画を行います．
描画としてはSTFTによる音声の周波数分布を表現しており，横軸に周波数，縦軸にデシベルをとっています．
正直Reactには詳しくないので，ここだけはGemini君に丸投げしました．
彼曰く

> Reactでは、頻繁な再レンダリングを防ぐために `useRef` を活用して `AudioContext` や `AnalyserNode` を管理します。
> 受信データにはSSRCが含まれているため、ユーザーごとにオーディオノードを作成し、色分けして可視化します。

> **工夫した点:**
> * **Canvas描画**: Reactのレンダリングサイクル外（`requestAnimationFrame`）で直接Canvas APIを叩くことで高速描画を実現。
> * **Base64デコード**: GoのJSON出力は `[]byte` がBase64になるため、JS側で `atob` を経由して `Float32Array` に戻す処理を実装。

# 実行結果
実行結果としては，以下の画像のように期待通りの結果が得られました．
もう少しページをきれいにしたい気もしましたが，とりあえずはこの程度です．

![](/images/20251206_hoge/002727.png)

また，複数人で接続した場合には，自動的に画面が分割されるようにしています．

![](/images/20251206_hoge/011003.png)

---

## まとめ
Go言語を中心とした実装で，discordのVCで送信された音声を可視化することに成功しました．
気になる点は多々ありますが，とりあえず動いたのでヨシ！
今後は今回のサーバ内で軽量な音声認識モデルを動作させ，TTSならぬSTT Botを構築したいと思います．
